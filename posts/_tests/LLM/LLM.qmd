---
title: Large Language Models
date: 2023/09/07
date-modified: last-modified
categories: 
  - LLM
  - transformers

image: transformer.png

format:
  html: default
  revealjs:
     output-file: revealjs.html 
---

## Large Language Models in Practice
Here I show how to use the transformers package from HuggingFace

### Setup

``` {python}
#| label: setup
#| warning: false

from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, GenerationConfig

# some model names --> https://huggingface.co/models
models=['google/flan-t5-base','google/flan-t5-large'] 
mn = models[0] # pick a small model

model   = AutoModelForSeq2SeqLM.from_pretrained(mn) # create model      
inp_em  = model.get_input_embeddings()              # function for input embedding
tok     = AutoTokenizer.from_pretrained(mn)         # pick a tokenizer (automatically)
config  = GenerationConfig(max_new_tokens=200)      # set config variables
```

### Use Model
``` {python}
input = "What colour is the sky?"

tokens = tok(input, return_tensors='pt')                     # string2token2tensors  
output = model.generate(**tokens, generation_config=config)  # generate answer

print('input:   ', input) 
# print output
# in embedding space
print('output:   ', output)                                  
# in word space
print('output (decoded):  ', tok.batch_decode(output, skip_special_tokens=True)) 
```

### Explore tokens

``` {python}
token_words = tok.tokenize(input)          # string2words (human representation, not used here)

token_ids = tokens['input_ids'][0]         # IDs  from tokens
token_em  = inp_em(token_ids)              # embeddings
print('token words:', token_words)
print('token ids:', token_ids)
print('token embeddings:', token_em)
```

## References

-  https://www.youtube.com/watch?v=tL1zltXuHO8
-  https://github.com/huggingface/transformers/tree/main/notebooks 


::: {.callout-tip collapse="true"}
#### watermark

```{python}
import watermark
import pkg_resources

#import os
#print("Local variables:", locals())
#print("Global variables:", globals())

# Display watermark information
print(watermark.watermark())

# Get installed module versions
installed_packages = pkg_resources.working_set

# Print module versions
print("Installed Packages:")
for package in installed_packages:
    print(package.key, package.version)
```
:::
