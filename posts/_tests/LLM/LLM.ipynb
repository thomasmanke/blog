{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {},
      "source": [
        "---\n",
        "title: Large Language Models\n",
        "date: 2023/09/07\n",
        "date-modified: last-modified\n",
        "categories: \n",
        "  - LLM\n",
        "  - transformers\n",
        "\n",
        "image: transformer.png\n",
        "\n",
        "format:\n",
        "  html: default\n",
        "  revealjs:\n",
        "     output-file: revealjs.html \n",
        "---"
      ],
      "id": "dcc9295b"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Large Language Models in Practice\n",
        "Here I show how to use the transformers package from HuggingFace\n",
        "\n",
        "### Setup\n"
      ],
      "id": "1b858264"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label: setup\n",
        "#| warning: false\n",
        "\n",
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, GenerationConfig\n",
        "\n",
        "# some model names --> https://huggingface.co/models\n",
        "models=['google/flan-t5-base','google/flan-t5-large'] \n",
        "mn = models[0] # pick a small model\n",
        "\n",
        "model   = AutoModelForSeq2SeqLM.from_pretrained(mn) # create model      \n",
        "inp_em  = model.get_input_embeddings()              # function for input embedding\n",
        "tok     = AutoTokenizer.from_pretrained(mn)         # pick a tokenizer (automatically)\n",
        "config  = GenerationConfig(max_new_tokens=200)      # set config variables"
      ],
      "id": "setup",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Use Model\n"
      ],
      "id": "3c6d8702"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "input = \"What colour is the sky?\"\n",
        "\n",
        "tokens = tok(input, return_tensors='pt')                     # string2token2tensors  \n",
        "output = model.generate(**tokens, generation_config=config)  # generate answer\n",
        "\n",
        "print('input:   ', input) \n",
        "# print output\n",
        "# in embedding space\n",
        "print('output:   ', output)                                  \n",
        "# in word space\n",
        "print('output (decoded):  ', tok.batch_decode(output, skip_special_tokens=True)) "
      ],
      "id": "ad0e5b48",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Explore tokens\n"
      ],
      "id": "e5a27fd7"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "token_words = tok.tokenize(input)          # string2words (human representation, not used here)\n",
        "\n",
        "token_ids = tokens['input_ids'][0]         # IDs  from tokens\n",
        "token_em  = inp_em(token_ids)              # embeddings\n",
        "print('token words:', token_words)\n",
        "print('token ids:', token_ids)\n",
        "print('token embeddings:', token_em)"
      ],
      "id": "6403405b",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## References\n",
        "\n",
        "-  https://www.youtube.com/watch?v=tL1zltXuHO8\n",
        "-  https://github.com/huggingface/transformers/tree/main/notebooks \n",
        "\n",
        "\n",
        "::: {.callout-tip collapse=\"true\"}\n",
        "#### watermark\n"
      ],
      "id": "10eba667"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import watermark\n",
        "import pkg_resources\n",
        "\n",
        "#import os\n",
        "#print(\"Local variables:\", locals())\n",
        "#print(\"Global variables:\", globals())\n",
        "\n",
        "# Display watermark information\n",
        "print(watermark.watermark())\n",
        "\n",
        "# Get installed module versions\n",
        "installed_packages = pkg_resources.working_set\n",
        "\n",
        "# Print module versions\n",
        "print(\"Installed Packages:\")\n",
        "for package in installed_packages:\n",
        "    print(package.key, package.version)"
      ],
      "id": "913af87c",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ":::"
      ],
      "id": "841fadbf"
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}