{
  "hash": "62b8bf62a31374ab7ff2dafb198e5f9b",
  "result": {
    "markdown": "---\ntitle: \"03: Getting Data In and Out\"\nauthor: \"Thomas Manke\"\ndate:  \"2023-03-26\"\ncategories:\n  - I/O\n  - R scripts\nformat:\n  html:\n    code-fold: true\n#    toc: yes\n#    toc_depth: 2\n---\n\n\n\n\n\n**Goal**: Ultimately we want to access our own data and write results to file.\n\n## Lecture material\n\nThis lecture series is written in R Markdown and is publically available as github repository.\n\n![Github link. https://github.com/maxplanck-ie/Rintro.git --\\> branch: 2023.03 !!](images/Rintro2023_QR.png)\n\n> Be aware that this course has seen various iterations - selecting the **correct** branch is crucial to avoid mix ups\n\nYou can access this material in various different ways:\n\n-   download as zip archive and unpack\n-   Rstudio/Git: open a new Rproject (\"New Project \\> Version Control \\> Git \\> ) and provide the same link as Repository URL. Find the `git` tab and make sure to select the relevant branch\"2023.03\"\n\n**Notice 1**:\\\nThe rmd files are provided for your convenience. This should save some typing (and common errors).\\\nHowever, this is an **interactive** course, so please use the code, understand it, change it, and break it !\n\n**Notice 2**:\\\nWe may update this material during the course ! If you want to retain and edit your own material make sure to save it somewhere differently.\\\nIf you use git you might want to checkout a **different** local branch and pull only to the original branch if an update is announced.\n\n------------------------------------------------------------------------\n\n## CSV files\n\nComma-separated text files (ASCII) are both human and machine readible. Other separators may be chosen (tab or \"\\|\"). This format is frequently used for simple data, such as rows of different samples/observations and columns of multiple variables (per sample)\n\n**Important:** Make sure that you know the precise location of your data file and provide this as filename.\n\nTopics:\n\n-   home and working directory\n-   relative and absolute path\n\n\n::: {.cell hash='03_GettingData_cache/html/csv_dfe896771e7908906d44b4ab9a04ddfc'}\n\n```{.r .cell-code}\ngetwd()                     # working directory\ndir()                       # display content\nfilename='data/iris.csv' # relative to wd\nd = read.csv(filename)      # file content --> memory (d)\nstr(d)\n```\n:::\n\n\nThere are many different ways to load such data into memory and to customize the loading.\n\n**Tasks:** - Explore ?read.csv to get a first overview how this function can be customized. - How would you read only the first 10 lines? - Explore the data object d - *Optional bonus:* try your own file and brace! Is it clean enough?\n\n## From URL\n\nNotice that files do not need to be available locally, but might be provided by some URL.\n\nBe aware that in those cases there might be significant reduced loading speed, depending on your network connections.\n\n\n::: {.cell hash='03_GettingData_cache/html/url_8b4a5aaa2e1bf12cb169d881c87645fb'}\n\n```{.r .cell-code}\nfilename='https://raw.githubusercontent.com/maxplanck-ie/Rintro/2023.03/data/iris.tsv'\nd = read.csv(filename, sep='\\t')  \nstr(d)\n```\n:::\n\n\n## Compressed formats\n\nEspecially for big data it is common to store them in compressed format (e.g. \\*gz) to reduced the storage footprint and speed-up data transfer. Such files are not human readable (binary) can also be read\n\n\n::: {.cell hash='03_GettingData_cache/html/gzip_8d3486075d0913e214c4a60b4b50ef6c'}\n\n```{.r .cell-code}\ncmd = \"gunzip -c data/iris.tsv.gz\"   # command to uncompress\nd = read.csv(pipe(cmd), sep='\\t')       # read as pipe\nstr(d)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n'data.frame':\t150 obs. of  5 variables:\n $ Sepal.Length: num  5.1 4.9 4.7 4.6 5 5.4 4.6 5 4.4 4.9 ...\n $ Sepal.Width : num  3.5 3 3.2 3.1 3.6 3.9 3.4 3.4 2.9 3.1 ...\n $ Petal.Length: num  1.4 1.4 1.3 1.5 1.4 1.7 1.4 1.5 1.4 1.5 ...\n $ Petal.Width : num  0.2 0.2 0.2 0.2 0.2 0.4 0.3 0.2 0.2 0.1 ...\n $ Species     : chr  \"setosa\" \"setosa\" \"setosa\" \"setosa\" ...\n```\n:::\n:::\n\n\n------------------------------------------------------------------------\n\n## Writing data\n\nThere are many ways to save data to text files. One of the simplest uses `write.csv`.\n\n\n::: {.cell hash='03_GettingData_cache/html/write_csv_b48a78072ef5ca78818b56c66b45c5cb'}\n\n```{.r .cell-code}\nwrite.csv(iris, file=\"iris.csv\", row.names=FALSE, quote=FALSE)\n```\n:::\n\n\nFor large data you may prefer to write compressed version:\n\n\n::: {.cell hash='03_GettingData_cache/html/write_gz_8bb4b0e31652fb323581a7bd1e788623'}\n\n```{.r .cell-code}\nwrite.csv(iris, gzfile(\"output/iris.csv.gz\"))\n```\n:::\n\n\n**Task**:\n\n-   Change some of the parameters (row.names, quote) and observed their effect on the resulting file\n-   Save only the subset of flowers where Species=\"setosa\" to a file setosa.tsv\n\n\n::: {.cell hash='03_GettingData_cache/html/unnamed-chunk-7_412002638acd1c844ef11ce56c2bd1e3'}\n\n:::\n\n\n## RData\n\nIn the context of the R-programming language, RData is a very convenient (binary) format that can be used to save multiple data structures or even whole environments It's very efficient when you exchange your data with other R-users (or your future self)\n\n### Specific objects\n\n\n::: {.cell hash='03_GettingData_cache/html/rdata_16b21680e8bc3adfd2c8b8666d1960a1'}\n\n```{.r .cell-code}\nd = iris              # copy of iris data\nfn=\"output/iris.RData\"       # filename (and extension) of choice\nsave(d, file=fn)\nrm(d)                 # remove object d for illustration - and watch global env\nload(fn)              # reload object d from file - and watch global env\n```\n:::\n\n\n### Task: All objects\n\nSometimes we want to save all objects and variable that have accumulated in the \"Global Environment\" - just to be sure. This task test some jargon, familiarity with directory structure and ability to find help. Please try it yourself.\n\n-   Create a new data object for the iris data set as before *and* additional variables for your favorite numbers and perhaps some favorite strings.\n-   Save the whole environment (using `save.image()`)\n-   Delete the whole environment aka \"workspace\"; e.g. using `rm(list=ls())`\n-   Reload the environment and confirm that you successfully recreated all objects\n-   Determine your current working directory (\\>getwd())\n-   Locate saved image on disk and inspect its size. Delete it if you prefer.\n\n\n::: {.cell hash='03_GettingData_cache/html/unnamed-chunk-9_b4a675127757cf73b565cbb8d2b7101b'}\n\n```{.r .cell-code}\n# your code snippet here\n```\n:::\n\n::: {.cell hash='03_GettingData_cache/html/rdat_env_c940fab7cf2e118b16bfb9e3758747b5'}\n\n:::\n\n\n**Notice**: The suffix is not strictly necessary, but it is best practice and used consistently by the community.\n\n------------------------------------------------------------------------\n\n# R Scripts\n\nTypical data analyses involve many successive steps.\\\nTo record everything that was done - and ultimately to be able to reproduce this - we use scripts.\n\nBasically these are just lines of code that are collected in a text file.\n\nIn Rstudio they can be created using `File > New File > R script`\n\n**Task** (10 min):\n\n-   Create a new R-script `filter_iris.R` to do the following:\n    -   Starting from the pre-compiled `iris` data, create a new `data_frame d` of all flowers where `Sepal.Length` is greater or equal to 7 cm.\n    -   determine the number flower in the new `data_frame`. Save this number as variable `nf`\n    -   How many different species are in the new data_frame. Save this number as variable `ns` (hint: there are two useful functions: `unique()` and `length()`)\n    -   write the new `data_frame d` in comma seperated file `iris_big_sepal.csv`\n    -   save the whole environment in a file `analysis.RData`\n    -   delete all variables in the environment\n-   Save the script and run it (source)\n-   Bonus: Delete all whole environment reload it from the image file\n\n**Query**: After the filtering, how many flowers and how many species are left?\n\n------------------------------------------------------------------------\n\n# Review\n\n-   Many different data sources, formats & structures\n    -   text files: *.tsv,* .csv, ...\n    -   compressed files: \\*.bed.gz\n    -   application specific: .*RData, (.*xls)\n-   Reading Data: many ways\n    -   read.csv(), read.table(), scan(), ...\n    -   from URL\n    -   customization with parameters\n    -   and there is more: special packages\n-   Writing Data: many ways\n    -   write.csv()\n    -   save() $\\to$ load()\n    -   save.image() $\\to$ load()\n-   Data I/O can be challenging:\n    -   file $\\to$ memory\n    -   know your paths, format, type, size\n    -   ensure clean and structured data\n    -   bring time and patience\n-   R scripts: writing and running (source)\n\n------------------------------------------------------------------------\n\n<br><br><br>\n\n# Appendix: reality of I/O\n\nMany external data is badly formatted, leading to much wasted time - before any analysis.\n\nThe code snippets below are not run - but try them out\n\n\n::: {.cell hash='03_GettingData_cache/html/trial_and_error_bcebd951aef2c918e7378c50a622f7d5'}\n\n```{.r .cell-code}\nfile=\"data/GeneList.tsv\"     \n# file=\"https://raw.githubusercontent.com/maxplanck-ie/Rintro/master/data/GeneList.tsv\"  \nread.csv(file)      \nread.csv(file, comment.char = \"%\")                        # comment lines\nread.csv(file, comment.char = \"%\", sep=\"\\t\")              # separators\n```\n:::\n\n::: {.cell hash='03_GettingData_cache/html/process_NA_ce03ef175e4cc02e656f1eb06e70a9aa'}\n\n```{.r .cell-code}\n# use ncol, is.na(), na.omit()\nic = colSums(is.na(d)) == ncol(d) # columns where all enries are NA\nd1 = d[, !ic]                     # exclude those columns\n\nd1\nna.omit(d) \nna.omit(d1)\n```\n:::\n\n\n**Messages:**\n\n-   This file is a mess\n-   Many data come like this\n-   read functions have many parameters for better control\n-   there are also other dedicated software packages to help (somewhat)\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}