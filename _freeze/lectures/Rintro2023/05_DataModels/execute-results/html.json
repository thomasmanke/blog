{
  "hash": "d920b66cb202f6db7bdf3ff1a0d3fa81",
  "result": {
    "markdown": "---\ntitle: \"05: Data Modeling\"\nauthor: \"Thomas Manke\"\ndate:  \"2023-03-26\"\ncategories:\n  - linear model\n  - class\n  - anova\n  - factors\n#format:\n#  html:\n#    toc: true\n#    toc_depth: 2\n#    code_fold: true\n---\n\n\n\n\n# Recap: All-Against-All Correlations\n\n**Task**: remove the Species variable from \"iris\" and store the result in a new data.frame \"niris\"\n\n\n::: {.cell hash='05_DataModels_cache/html/unnamed-chunk-2_3c1f88e471315244da85523bd476917d'}\n\n```{.r .cell-code}\nniris=iris[,-5]  # generate new data frame without species variable\nstr(niris)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n'data.frame':\t150 obs. of  4 variables:\n $ Sepal.Length: num  5.1 4.9 4.7 4.6 5 5.4 4.6 5 4.4 4.9 ...\n $ Sepal.Width : num  3.5 3 3.2 3.1 3.6 3.9 3.4 3.4 2.9 3.1 ...\n $ Petal.Length: num  1.4 1.4 1.3 1.5 1.4 1.7 1.4 1.5 1.4 1.5 ...\n $ Petal.Width : num  0.2 0.2 0.2 0.2 0.2 0.4 0.3 0.2 0.2 0.1 ...\n```\n:::\n:::\n\n\n**Task**: Generate all-against-all correlation plot\n\n\n::: {.cell hash='05_DataModels_cache/html/unnamed-chunk-3_8e39318b6baeb0ab5f13426676091d12'}\n\n```{.r .cell-code}\n# assign species-colors to each observation \ncols = iris$Species                        # understand how color is defined\npairs(niris, col=cols, lower.panel=NULL)   # \"cols\" was defined in task above\n```\n\n::: {.cell-output-display}\n![](05_DataModels_files/figure-html/unnamed-chunk-3-1.png){width=672}\n:::\n:::\n\n\n------------------------------------------------------------------------\n\n# From Correlations to Models\n\n**Goal:**\n\nModel some dependent variable y as function of other explanatory variables x (features)\n\n$$\ny = f(\\theta, x) = \\theta_1 x +  \\theta_0\n$$\n\nFor $N$ data points, choose parameters $\\theta$ by ordinary least squares:\n\n$$\nRSS=\\sum_{i=1}^{N} (y_i - f(\\theta, x_i))^2 \\to min\n$$\n\nEasy in R:\n\n\n::: {.cell hash='05_DataModels_cache/html/ols_7a20a7d2b1cf12176f58923846a4f9d5'}\n\n```{.r .cell-code}\nplot(Petal.Width ~ Petal.Length, data=iris, col=Species) # use model (\"formula\") notation\nfit=lm(Petal.Width ~ Petal.Length, data=iris)       # fit a linear model\nabline(fit, lwd=3, lty=2)                           # add regression line\n```\n\n::: {.cell-output-display}\n![](05_DataModels_files/figure-html/ols-1.png){width=672}\n:::\n:::\n\n\n**Query**: What class is the object `fit`?\n\n**Task**: Extract the coefficients of the fitted line.\n\n\n::: {.cell hash='05_DataModels_cache/html/unnamed-chunk-5_248a636ddf4e6e6320ccb5a3d8711222'}\n::: {.cell-output .cell-output-stdout}\n```\n (Intercept) Petal.Length \n  -0.3630755    0.4157554 \n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n (Intercept) Petal.Length \n  -0.3630755    0.4157554 \n```\n:::\n:::\n\n\n# Reporting the fit (model)\n\n\n::: {.cell hash='05_DataModels_cache/html/lm_summary_ba39f40e845e16809ffc6b6d978bae35'}\n\n```{.r .cell-code}\nsummary(fit)        # summary() behaves differently for fit objects\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = Petal.Width ~ Petal.Length, data = iris)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.56515 -0.12358 -0.01898  0.13288  0.64272 \n\nCoefficients:\n              Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  -0.363076   0.039762  -9.131  4.7e-16 ***\nPetal.Length  0.415755   0.009582  43.387  < 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.2065 on 148 degrees of freedom\nMultiple R-squared:  0.9271,\tAdjusted R-squared:  0.9266 \nF-statistic:  1882 on 1 and 148 DF,  p-value: < 2.2e-16\n```\n:::\n\n```{.r .cell-code}\ncoefficients(fit)   # more functions for specific elements\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n (Intercept) Petal.Length \n  -0.3630755    0.4157554 \n```\n:::\n\n```{.r .cell-code}\nconfint(fit)        # Try to change the confidence level: ?confint\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n                  2.5 %     97.5 %\n(Intercept)  -0.4416501 -0.2845010\nPetal.Length  0.3968193  0.4346915\n```\n:::\n:::\n\n\nThis is a good fit as suggested by a\n\n-   small residual standard error\n-   a large coefficient of variation $R^2$\n-   a small p-value\n-   and by visualization\n\n$$\nR^2 = 1 - \\frac{RSS}{TSS} = 1 - \\frac{\\sum_i(y_i - y(\\theta,x_i))^2}{\\sum_i(y_i-\\bar{y})^2}\n$$ There are manny more methods to access information for the `lm` class\n\n\n::: {.cell hash='05_DataModels_cache/html/class_methods_8339eabe708fe2e8c0ecbf7393a60b59'}\n\n```{.r .cell-code}\nmethods(class='lm')\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n [1] add1           alias          anova          case.names     coerce        \n [6] confint        cooks.distance deviance       dfbeta         dfbetas       \n[11] drop1          dummy.coef     effects        extractAIC     family        \n[16] formula        hatvalues      influence      initialize     kappa         \n[21] labels         logLik         model.frame    model.matrix   nobs          \n[26] plot           predict        print          proj           qr            \n[31] residuals      rstandard      rstudent       show           simulate      \n[36] slotsFromS3    summary        variable.names vcov          \nsee '?methods' for accessing help and source code\n```\n:::\n:::\n\n\n# Predictions (with confidence intervals)\n\n\n::: {.cell hash='05_DataModels_cache/html/predictions_a5f7bdb734db8e994ae86e76e65a2edb'}\n\n```{.r .cell-code}\nx=iris$Petal.Length                       # explanatory variable from fit (here:Petal.Length)\nxn=seq(min(x), max(x), length.out = 100)  # define range of new explanatory variables\nndf=data.frame(Petal.Length=xn)           # put them into new data frame\n\np=predict(fit, ndf, interval = 'confidence' , level = 0.95)\nplot(Petal.Width ~ Petal.Length, data=iris, col=Species)\nlines(xn, p[,\"lwr\"] )\nlines(xn, p[,\"upr\"] )\n\n#some fancy filling\npolygon(c(rev(xn), xn), c(rev(p[ ,\"upr\"]), p[ ,\"lwr\"]), col = rgb(1,0,0,0.5), border = NA)\n```\n\n::: {.cell-output-display}\n![](05_DataModels_files/figure-html/predictions-1.png){width=672}\n:::\n\n```{.r .cell-code}\n## using ggplot2 - full introduction later\n#library(ggplot2)\n#g = ggplot(iris, aes(Petal.Length, Petal.Width, colour=Species))\n#g + geom_point() + geom_smooth(method=\"lm\", se=TRUE, color=\"red\") + geom_smooth(method=\"loess\", colour=\"blue\")\n```\n:::\n\n\n# Poor Fit\n\nJust replace \"Petal\" with \"Sepal\"\n\n\n::: {.cell hash='05_DataModels_cache/html/unnamed-chunk-9_212650efd60c939ad497100320ce00de'}\n\n```{.r .cell-code}\nplot(Sepal.Width ~ Sepal.Length, data=iris, col=cols)  \nfit1=lm(Sepal.Width ~ Sepal.Length, data=iris)     \nabline(fit1, lwd=3, lty=2)    \n```\n\n::: {.cell-output-display}\n![](05_DataModels_files/figure-html/unnamed-chunk-9-1.png){width=672}\n:::\n\n```{.r .cell-code}\nconfint(fit1)                     # estimated slope is indistinguishable from zero\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n                  2.5 %     97.5 %\n(Intercept)   2.9178767 3.92001694\nSepal.Length -0.1467928 0.02302323\n```\n:::\n\n```{.r .cell-code}\nsummary(fit1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = Sepal.Width ~ Sepal.Length, data = iris)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-1.1095 -0.2454 -0.0167  0.2763  1.3338 \n\nCoefficients:\n             Estimate Std. Error t value Pr(>|t|)    \n(Intercept)   3.41895    0.25356   13.48   <2e-16 ***\nSepal.Length -0.06188    0.04297   -1.44    0.152    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.4343 on 148 degrees of freedom\nMultiple R-squared:  0.01382,\tAdjusted R-squared:  0.007159 \nF-statistic: 2.074 on 1 and 148 DF,  p-value: 0.1519\n```\n:::\n:::\n\n\n*Interpretation*: slope is not significantly distinct from 0.\n\n**Task**: Use the above template to make predictions for the new poor fit.\n\n\n::: {.cell hash='05_DataModels_cache/html/unnamed-chunk-10_dddaaa863ef5a5789658ae17727f29bd'}\n::: {.cell-output-display}\n![](05_DataModels_files/figure-html/unnamed-chunk-10-1.png){width=672}\n:::\n:::\n\n\n# Factorial variables as predictors\n\nIn the iris example the \"Species\" variable is a factorial (categorical) variable with 3 levels. Other typical examples: different experimental conditions or treatments.\n\n\n::: {.cell hash='05_DataModels_cache/html/unnamed-chunk-11_56ecfa37bdfa974fa1936c5b69e6361d'}\n\n```{.r .cell-code}\nplot(Petal.Width ~ Species, data=iris)\n```\n\n::: {.cell-output-display}\n![](05_DataModels_files/figure-html/unnamed-chunk-11-1.png){width=672}\n:::\n\n```{.r .cell-code}\nfit=lm(Petal.Width ~ Species, data=iris)\nsummary(fit)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = Petal.Width ~ Species, data = iris)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-0.626 -0.126 -0.026  0.154  0.474 \n\nCoefficients:\n                  Estimate Std. Error t value Pr(>|t|)    \n(Intercept)        0.24600    0.02894    8.50 1.96e-14 ***\nSpeciesversicolor  1.08000    0.04093   26.39  < 2e-16 ***\nSpeciesvirginica   1.78000    0.04093   43.49  < 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.2047 on 147 degrees of freedom\nMultiple R-squared:  0.9289,\tAdjusted R-squared:  0.9279 \nF-statistic:   960 on 2 and 147 DF,  p-value: < 2.2e-16\n```\n:::\n:::\n\n\n*Interpretation*:\n\n-   \"setosa\" (1st species) has mean Petal.Width=0.246(29) - reference baseline\n-   \"versicolor\" (2nd species) has mean Petal.Width = Petal.Width(setosa) + 1.08(4)\n-   \"virginica\" (3rd species) has mean Petal.Width = Petal.Width(setosa) + 1.78(4)\n\n# Anova\n\n`summary(fit)` contains information on the individual coefficients. They are difficult to interpret\n\n\n::: {.cell hash='05_DataModels_cache/html/anova_f0d8562b3966a90975cf0c50d1fdb4bb'}\n\n```{.r .cell-code}\nanova(fit)    \n```\n\n::: {.cell-output .cell-output-stdout}\n```\nAnalysis of Variance Table\n\nResponse: Petal.Width\n           Df Sum Sq Mean Sq F value    Pr(>F)    \nSpecies     2 80.413  40.207  960.01 < 2.2e-16 ***\nResiduals 147  6.157   0.042                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n:::\n:::\n\n\n**Interpretation**: variable \"Species\" accounts for much variation in \"Petal.Width\"\n\n------------------------------------------------------------------------\n\n# More complicated models\n\nDetermine residual standard error `sigma` for different fits with various complexity\n\n\n::: {.cell hash='05_DataModels_cache/html/unnamed-chunk-13_d1ba52af041d0ea573f9eff8e3450606'}\n\n```{.r .cell-code}\nfit=lm(Petal.Width ~ Petal.Length, data=iris)\npaste(toString(fit$call), sigma(fit))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"lm, Petal.Width ~ Petal.Length, iris 0.206484348913609\"\n```\n:::\n\n```{.r .cell-code}\nfit=lm(Petal.Width ~ Petal.Length + Sepal.Length, data=iris)  # function of more than one variable\npaste(toString(fit$call), sigma(fit))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"lm, Petal.Width ~ Petal.Length + Sepal.Length, iris 0.204445704742963\"\n```\n:::\n\n```{.r .cell-code}\nfit=lm(Petal.Width ~ Species, data=iris)                      # function of categorical variables\npaste(toString(fit$call), sigma(fit))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"lm, Petal.Width ~ Species, iris 0.204650024805914\"\n```\n:::\n\n```{.r .cell-code}\nfit=lm(Petal.Width ~ . , data=iris)                           # function of all other variable (numerical and categorical)\npaste(toString(fit$call), sigma(fit))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"lm, Petal.Width ~ ., iris 0.166615943019283\"\n```\n:::\n:::\n\n\n... more complex models tend to have smaller residual standard error (overfitting?)\n\n------------------------------------------------------------------------\n\n# Model Checking: Diagnostic Plots\n\n\"fit\" is a large object of the lm-class which contains also lots of diagnostic informmation. Notice how the behaviour of \"plot\" changes.\n\n\n::: {.cell hash='05_DataModels_cache/html/fit_diag_0e285779344c5908af0881f0de9c92f2'}\n\n```{.r .cell-code}\nfit=lm(Petal.Width ~ ., data=iris)\nop=par(no.readonly=TRUE)   # safe only resettable graphical parameters, avoids many warnings\npar(mfrow=c(2,2))          # change graphical parameters: 2x2 images on device\nplot(fit,col=iris$Species) # four plots rather than one\n```\n\n::: {.cell-output-display}\n![](05_DataModels_files/figure-html/fit_diag-1.png){width=672}\n:::\n\n```{.r .cell-code}\npar(op)                    # reset graphical parameters\n```\n:::\n\n\nmore examples here: http://www.statmethods.net/stats/regression.html\n\nLinear models $y_i=\\theta_0 + \\theta_1 x_i + \\epsilon_i$ make certain assumptions ($\\epsilon_i \\propto N(0,\\sigma^2)$)\n\n-   residuals $\\epsilon_i$ are independent from each other (non-linear patterns?)\n-   residuals are normally distributed\n-   have equal variance $\\sigma^2$ (homoscedascity)\n-   are there outliers (large residuals) or observations with strong influence on fit\n\n------------------------------------------------------------------------\n\n# Review\n\n-   dependencies between variable can often be modeled\n-   linear model lm(): fitting, summary and interpretation\n-   correlation coefficients can be misleading\n-   linear models may not be appropriate. \\>example(anscombe)\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}